{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7fb83e",
   "metadata": {},
   "source": [
    "# Accurate Meal Model (Reversal Sessions)\n",
    "\n",
    "This notebook revisits the reversal meal classification workflow. We gather meals directly from the current FED3 session interface, inspect clusters by pellet count, and evaluate pre-trained LSTM/CNN classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f17e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'scripts'))\n",
    "\n",
    "from scripts.preprocessing import build_session_catalog, session_cache\n",
    "from scripts.meals import analyze_meals\n",
    "from scripts.meal_classifiers import (\n",
    "    RNNClassifier,\n",
    "    CNNClassifier,\n",
    "    TimeSeriesDataset,\n",
    "    train,\n",
    "    evaluate_meals_by_groups,\n",
    "    evaluate_meals_on_new_data,\n",
    ")\n",
    "from scripts.unsupervised_helpers import (\n",
    "    find_k_by_elbow,\n",
    "    fit_model_single,\n",
    "    collect_meals_from_categories,\n",
    "    data_padding,\n",
    "    read_data,\n",
    "    update_data,\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88e773",
   "metadata": {},
   "source": [
    "## Load reversal sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_ROOT = PROJECT_ROOT / 'sample_data'\n",
    "GROUP_MAP_PATH = PROJECT_ROOT / 'group_map.json'\n",
    "\n",
    "session_cache.cache_clear()\n",
    "SESSIONS, GROUPINGS = build_session_catalog(SAMPLE_ROOT, GROUP_MAP_PATH)\n",
    "\n",
    "REV_SESSIONS = {}\n",
    "for group, session_types in GROUPINGS.items():\n",
    "    rev_keys = session_types.get('REV', [])\n",
    "    rev_ids = [key.session_id for key in rev_keys]\n",
    "    if rev_ids:\n",
    "        REV_SESSIONS[group] = [SESSIONS[sid] for sid in rev_ids]\n",
    "\n",
    "if not REV_SESSIONS:\n",
    "    raise RuntimeError('No reversal sessions found. Ensure sample data includes REV sessions.')\n",
    "\n",
    "GROUP_NAMES = sorted(REV_SESSIONS.keys())\n",
    "GROUP_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4728ff",
   "metadata": {},
   "source": [
    "## Extract meal sequences per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46188f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meal_sequences(session_list, time_threshold=60, pellet_threshold=2, counts=(3, 4, 5)):\n",
    "    sequences = {cnt: [] for cnt in counts}\n",
    "    session_ratios = []\n",
    "    for session in session_list:\n",
    "        meals_with_acc, good_mask, _ = analyze_meals(\n",
    "            session.raw.copy(),\n",
    "            time_threshold=time_threshold,\n",
    "            pellet_threshold=pellet_threshold,\n",
    "            model_type='cnn',\n",
    "        )\n",
    "        total = len(good_mask)\n",
    "        ratio = float(good_mask.sum()) / total if total else 0.0\n",
    "        session_ratios.append(ratio)\n",
    "        for _, padded in meals_with_acc:\n",
    "            valid = [value for value in padded if value != -1]\n",
    "            pellet_cnt = len(valid) + 1\n",
    "            if pellet_cnt in sequences:\n",
    "                sequences[pellet_cnt].append(valid)\n",
    "    return sequences, session_ratios\n",
    "\n",
    "control_group = GROUP_NAMES[0]\n",
    "experiment_group = GROUP_NAMES[1] if len(GROUP_NAMES) > 1 else GROUP_NAMES[0]\n",
    "\n",
    "ctrl_sequences, ctrl_good_ratios = extract_meal_sequences(REV_SESSIONS[control_group])\n",
    "exp_sequences, exp_good_ratios = extract_meal_sequences(REV_SESSIONS[experiment_group])\n",
    "\n",
    "print(f'{control_group}: {len(ctrl_good_ratios)} sessions')\n",
    "print(f'{experiment_group}: {len(exp_good_ratios)} sessions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83488504",
   "metadata": {},
   "source": [
    "## Control group clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259eb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "control_configs = {\n",
    "    3: {'k': 4, 'good_clusters': [0, 3]},\n",
    "    4: {'k': 7, 'good_clusters': [1, 4]},\n",
    "    5: {'k': 8, 'good_clusters': [1, 3, 7]},\n",
    "}\n",
    "\n",
    "for pellet_cnt, cfg in control_configs.items():\n",
    "    data = ctrl_sequences.get(pellet_cnt, [])\n",
    "    if not data:\n",
    "        print(f'No control meals with {pellet_cnt} pellets.')\n",
    "        continue\n",
    "    print(f\"Control {pellet_cnt}-pellet meals: {len(data)} samples\")\n",
    "    find_k_by_elbow(data)\n",
    "    model, meals_by_category = fit_model_single(data, k=cfg['k'])\n",
    "    good_meals, bad_meals = collect_meals_from_categories(meals_by_category, cfg['good_clusters'])\n",
    "    update_data(DATA_DIR / 'CASK_ctrl_good.pkl', good_meals)\n",
    "    update_data(DATA_DIR / 'CASK_ctrl_bad.pkl', bad_meals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3c730",
   "metadata": {},
   "source": [
    "## Experimental group clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf43d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = {\n",
    "    3: {'k': 6, 'good_clusters': [0, 3]},\n",
    "    4: {'k': 9, 'good_clusters': [2, 6]},\n",
    "    5: {'k': 12, 'good_clusters': [1, 3, 6]},\n",
    "}\n",
    "\n",
    "for pellet_cnt, cfg in experiment_configs.items():\n",
    "    data = exp_sequences.get(pellet_cnt, [])\n",
    "    if not data:\n",
    "        print(f'No experimental meals with {pellet_cnt} pellets.')\n",
    "        continue\n",
    "    print(f\"Experiment {pellet_cnt}-pellet meals: {len(data)} samples\")\n",
    "    find_k_by_elbow(data)\n",
    "    model, meals_by_category = fit_model_single(data, k=cfg['k'])\n",
    "    good_meals, bad_meals = collect_meals_from_categories(meals_by_category, cfg['good_clusters'])\n",
    "    update_data(DATA_DIR / 'CASK_exp_good.pkl', good_meals)\n",
    "    update_data(DATA_DIR / 'CASK_exp_bad.pkl', bad_meals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e04bba",
   "metadata": {},
   "source": [
    "## Good meal proportion summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    control_group: {\n",
    "        'n_sessions': len(ctrl_good_ratios),\n",
    "        'mean': float(np.mean(ctrl_good_ratios)) if ctrl_good_ratios else 0.0,\n",
    "        'std': float(np.std(ctrl_good_ratios)) if ctrl_good_ratios else 0.0,\n",
    "    },\n",
    "    experiment_group: {\n",
    "        'n_sessions': len(exp_good_ratios),\n",
    "        'mean': float(np.mean(exp_good_ratios)) if exp_good_ratios else 0.0,\n",
    "        'std': float(np.std(exp_good_ratios)) if exp_good_ratios else 0.0,\n",
    "    },\n",
    "}\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec8b6c",
   "metadata": {},
   "source": [
    "## Prepare datasets for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_good = read_data(DATA_DIR / 'CASK_ctrl_good.pkl')\n",
    "ctrl_bad = read_data(DATA_DIR / 'CASK_ctrl_bad.pkl')\n",
    "exp_good = read_data(DATA_DIR / 'CASK_exp_good.pkl')\n",
    "exp_bad = read_data(DATA_DIR / 'CASK_exp_bad.pkl')\n",
    "\n",
    "print(f'Control labelled meals: good={len(ctrl_good)}, bad={len(ctrl_bad)}')\n",
    "print(f'Experiment labelled meals: good={len(exp_good)}, bad={len(exp_bad)}')\n",
    "\n",
    "ctrl_X = np.vstack((data_padding([meal[:] for meal in ctrl_good]), data_padding([meal[:] for meal in ctrl_bad])))\n",
    "ctrl_y = np.concatenate((np.zeros(len(ctrl_good)), np.ones(len(ctrl_bad))))\n",
    "exp_X = np.vstack((data_padding([meal[:] for meal in exp_good]), data_padding([meal[:] for meal in exp_bad])))\n",
    "exp_y = np.concatenate((np.zeros(len(exp_good)), np.ones(len(exp_bad))))\n",
    "\n",
    "X = np.vstack((ctrl_X, exp_X))\n",
    "y = np.concatenate((ctrl_y, exp_y))\n",
    "print('Dataset shape:', X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755b230",
   "metadata": {},
   "source": [
    "## Train LSTM/CNN classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbc7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch is None:\n",
    "    raise RuntimeError('PyTorch is required for training. Please install torch to continue.')\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "rnn_model = RNNClassifier(input_size=1, hidden_size=400, num_layers=2, num_classes=2)\n",
    "rnn_model = rnn_model.to(X_train.device)\n",
    "rnn_model = train(rnn_model, lr=1e-4, num_epochs=50, train_loader=train_loader, X_test_tensor=X_test, y_test_tensor=y_test)\n",
    "\n",
    "cnn_model = CNNClassifier(num_classes=2, maxlen=X.shape[1])\n",
    "cnn_model = cnn_model.to(X_train.device)\n",
    "cnn_model = train(cnn_model, lr=1e-3, num_epochs=50, train_loader=train_loader, X_test_tensor=X_test, y_test_tensor=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdabe14",
   "metadata": {},
   "source": [
    "## Evaluate pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53138e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch is None:\n",
    "    raise RuntimeError('PyTorch is required for evaluation. Please install torch to continue.')\n",
    "\n",
    "ctrl_tensor = torch.tensor(ctrl_X, dtype=torch.float32)\n",
    "ctrl_labels = torch.tensor(ctrl_y, dtype=torch.long)\n",
    "exp_tensor = torch.tensor(exp_X, dtype=torch.float32)\n",
    "exp_labels = torch.tensor(exp_y, dtype=torch.long)\n",
    "\n",
    "rnn_pretrained = RNNClassifier(input_size=1, hidden_size=400, num_layers=2, num_classes=2)\n",
    "cnn_pretrained = CNNClassifier(num_classes=2, maxlen=ctrl_X.shape[1])\n",
    "\n",
    "rnn_pretrained.load_state_dict(torch.load(PROJECT_ROOT / 'data' / 'LSTM_from_CASK.pth', map_location='cpu'))\n",
    "cnn_pretrained.load_state_dict(torch.load(PROJECT_ROOT / 'data' / 'CNN_from_CASK.pth', map_location='cpu'))\n",
    "\n",
    "print('Pre-trained RNN evaluation:')\n",
    "evaluate_meals_by_groups(rnn_pretrained, ctrl_tensor, ctrl_y, exp_tensor, exp_y)\n",
    "print('Pre-trained CNN evaluation:')\n",
    "evaluate_meals_by_groups(cnn_pretrained, ctrl_tensor, ctrl_y, exp_tensor, exp_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
